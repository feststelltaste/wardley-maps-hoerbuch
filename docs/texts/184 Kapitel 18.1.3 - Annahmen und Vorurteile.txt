Kapitel 18.1.3.: Annahmen und Vorurteile

   Annahmen sind eine sehr gefährliche Tätigkeit und eine, die mich immer wieder überrumpelt hat. In der Vergangenheit hatte ich angenommen, dass jeder weiß, wie man kartiert, aber die eigentliche Frage ist, warum habe ich das gedacht? Die Antwort in diesem Fall ist eine Voreingenommenheit, die als "false consensus bias" bekannt ist. Ich neige dazu, anzunehmen, dass, wenn ich etwas weiß, es auch jeder andere wissen muss. Das ist der Grund, warum ich sechs Jahre gebraucht habe, um herauszufinden, dass andere nicht kartieren. Das war auch der Grund für meine Annahmen in dem Papier "Better for Less"

   Wenn es um Voreingenommenheit bei Mäps geht, gibt es zwei Haupttypen, die Sie berücksichtigen müssen. Die erste ist die evolutionäre Voreingenommenheit und unsere Tendenz, etwas falsch zu behandeln, z. B. das, was ein Gebrauchsgegenstand ist, individuell zu gestalten. Wenn Sie mehrere Mäps vergleichen, können Sie diesen Einfluss verringern. Die zweite große und mächtige Gruppe von Verzerrungen sind kognitive Verzerrungen. Karten können hier helfen, aber nur, wenn Sie anderen erlauben, Ihre Karte zu hinterfragen. Die häufigsten und gefährlichsten Arten von kognitiven Voreingenommenheiten, mit denen ich konfrontiert wurde (und meine Beschreibung dieser als "häufigste und gefährlichste" ist eine weitere Voreingenommenheit), sind:      * Konfirmationsverzerrung*

   Eine Tendenz, Informationen in einer Weise zu akzeptieren oder zu interpretieren, die bestehende Vorurteile bestätigt. Zum Beispiel eine Gruppe, die sich an Informationen klammert, die ihre Verwendung eines Prozesses unterstützen, der sich von dem der Industrie unterscheidet und somit die Art und Weise rechtfertigt, wie sie ihn gebaut haben
     * Verlustaversionsverzerrung*

   Der Wert des Verlusts eines Objekts übersteigt den Wert seiner Anschaffung, z. B. der Sunk-Cost-Effekt. Beispiele: "Hätten wir dieses Geld nicht investiert, würden wir diesen Gegenstand nicht nutzen". Oft eine wichtige Ursache für Trägheit
     * Ergebnisverzerrung*

   Eine Tendenz, auf das tatsächliche Ergebnis zu schauen und nicht auf den Prozess, mit dem die Wahl getroffen wurde. Tritt häufig in Memen auf, die andere Unternehmen kopieren, wenn wenig bis kein Situationsbewusstsein vorhanden ist, z. B. "wir sollten wie Amazon sein"
     * Einsichtsverzerrung*

   Eine Tendenz, vergangene Ereignisse als vorhersehbarer zu sehen, als sie waren. Ein Beispiel wäre die Beschreibung der Entwicklung der Datenverarbeitung vom Mainframe zum Client/Server zur Cloud als eine Art vorbestimmter Weg. Das Problem ist, dass der "scheinbare" Weg, der auf einer hohen Ebene eingeschlagen wurde, davon abhängt, wie weit die zugrunde liegenden Komponenten entwickelt waren (z. B. Speicher, Verarbeitung, Netzwerk). Wenn Verarbeitung und Speicherung wesentlich teurer wären als das Netzwerk, würden wir zur Zentralisierung tendieren. Wenn hingegen das Netzwerk teurer wäre, würden wir zur Dezentralisierung tendieren
     * Kaskadenschräglage*

   Ein Glaube, der durch seine Wiederholung in der Öffentlichkeit an Plausibilität gewinnt, wie z.B. viele der falschen Mythen der Cloud, wie Amazons "Verkauf von freien Kapazitäten"
     * Messgeräteverzerrung*

   Das Problem der Vertrautheit und des Verlassens auf bekannte Werkzeuge oder Ansätze unter Ausschluss anderer Methoden. Zusammengefasst durch die Zeile "Wenn man nur einen Hammer hat, sieht alles wie ein Nagel aus."
     * Dispositionsverzerrung*

   Der Wunsch, nicht an Wert zu verlieren, d. h. der Verkauf von Vermögenswerten, die an Wert gewonnen haben, aber der Widerstand gegen den Verkauf von Vermögenswerten, die an Wert verloren haben, in der Hoffnung, dass sie sich erholen werden. Dies ist eine weitere häufige Quelle für Trägheit durch den Glauben, dass sich ein bestehender Geschäftszweig oder ein erworbener Vermögenswert, der sich schlecht entwickelt, erholen wird
     * Dunning-Kruger-Effekt*

   Tendenz der Unerfahrenen, ihr Können zu überschätzen und der Erfahrenen, es zu unterschätzen
     * Mit freundlicher Genehmigung bias*

   Eine Tendenz, dass Einzelne es vermeiden, ihre wahre Meinung zu sagen, um andere nicht zu verletzen, z. B. um nicht zwingend in Frage zu stellen, warum wir etwas tun, besonders wenn es als "Lieblingsprojekt" eines anderen angesehen wird
     * Ambiguity bias*

   Eine Tendenz, Ungewissheit zu vermeiden, wo es möglich ist, und / oder zu versuchen, Ungewissheit zu definieren, z. B. das Unbekannte zu spezifizieren
     * Überlebenszeitverzerrung*

   Es werden nur die Daten untersucht, die einen bestimmten Endzustand erreichen, und nicht die, die ihn nicht erreichen. Der Kern des Mappings ist ein Survivorship Bias. Die Evolutionskurve (beschrieben in xref:#chapter-7-finding-a-new-purpose[chapter 7]), die als Basis der x-Achse einer Abbildung verwendet wird, wurde aus Daten für Komponenten erstellt, die überlebt haben, um zu einem Gebrauchsgegenstand zu werden. Sie zeigt einen Pfad von "Wenn sich eine Komponente zu einem Commodity entwickelt, dann durchläuft sie diese Stufen". Aber was ist mit den Komponenten, die nicht überlebt haben? Leider war ich nicht in der Lage, ein anderes Muster zu erkennen, um sie zu erklären, als zu sagen, dass sie dem Pfad der Evolution folgten und in einer der Stufen starben. Am offensichtlichsten (weil wir Zugang zu Daten bekommen können), sterben Komponenten in der Stufe "Custom Built" und ich kann nur vermuten (weil es nahezu unmöglich ist, Daten zu bekommen), dass die häufigste Todesstufe die
   Entstehungsphase ist, in der der höchste Grad an Unsicherheit besteht. Natürlich sind Annahmen eine gefährliche Sache.

